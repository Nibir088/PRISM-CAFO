{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abac9e86-2d9d-463c-8ee5-d6960f617db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7f7cf70f954a19b2e1fad2683bfffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_377043/1166792405.py:46: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.asarray(x)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (59,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 237\u001b[39m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 187\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    186\u001b[39m     pred = sam(im)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m masks_all = \u001b[43m_extract_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m masks_all \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m masks_all.shape[\u001b[32m0\u001b[39m] == \u001b[32m0\u001b[39m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[skip] no masks from SAM2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36m_extract_masks\u001b[39m\u001b[34m(pred)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m masks = \u001b[43m_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36m_to_numpy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor): \u001b[38;5;28;01mreturn\u001b[39;00m x.detach().cpu().numpy()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (59,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# sam2_keep_masks_by_label_rules.py\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CSV_PATH  = Path(\"/project/biocomplexity/gza5dr/CAFO_Test/yolo_img_preds_all/detections.csv\")\n",
    "IMG_COL   = \"image\"\n",
    "BOX_COLS  = [\"x1\",\"y1\",\"x2\",\"y2\"]   # change if your CSV uses different names\n",
    "\n",
    "# We’ll auto-detect the label column from this list (first match wins).\n",
    "LABEL_CANDIDATES = [\"label\"]\n",
    "\n",
    "SKIP_DISCARD = False  # True → drop rows whose label == \"discard\"\n",
    "\n",
    "OUT_DIR   = Path(\"/project/biocomplexity/gza5dr/CAFO_Test/sam_on_yolo_all\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_ID  = \"facebook/sam2-hiera-large\"  # or \"facebook/sam2-hiera-small\"\n",
    "\n",
    "# Thresholds for the rules\n",
    "INSIDE_THRESH     = 0.90  # barn/building: fraction of the *mask* inside the bbox\n",
    "COVER_THRESH      = 0.40  # manure_pond: min fraction of the *box* covered by best mask\n",
    "OVERLAP_MIN_FRAC  = 0.80  # silo/feedlot/silage*/storage: min fraction of the *box* covered\n",
    "\n",
    "# NEW: Barn additional constraint — mask bbox area vs det bbox area\n",
    "BARN_MIN_SIZE_RATIO = 0.25  # keep only if area(mask_bbox)/area(det_bbox) >= this\n",
    "ANY_INSIDE_FRAC = 0.20   # keep mask if ≥20% of its pixels lie inside the bbox\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _open_pil(p: Path) -> Image.Image:\n",
    "    return Image.open(p).convert(\"RGB\")\n",
    "\n",
    "def _to_numpy(x):\n",
    "    if x is None: return None\n",
    "    if isinstance(x, torch.Tensor): return x.detach().cpu().numpy()\n",
    "    return np.asarray(x)\n",
    "\n",
    "def _extract_masks(pred):\n",
    "    \"\"\"\n",
    "    pred from HF pipeline(\"mask-generation\"). Return masks: (N,H,W) bool.\n",
    "    \"\"\"\n",
    "    if pred is None:\n",
    "        return None\n",
    "    if isinstance(pred, (list, tuple)):\n",
    "        if len(pred) == 0:\n",
    "            return None\n",
    "        pred = pred[0]\n",
    "    if not isinstance(pred, dict):\n",
    "        return None\n",
    "\n",
    "    masks = None\n",
    "    for k in [\"masks\", \"segments\", \"segmentation\"]:\n",
    "        if k in pred and pred[k] is not None:\n",
    "            masks = pred[k]\n",
    "            break\n",
    "    if masks is None:\n",
    "        return None\n",
    "\n",
    "    masks = _to_numpy(masks)\n",
    "    if masks is None:\n",
    "        return None\n",
    "    if masks.ndim == 2:\n",
    "        masks = masks[None, ...]\n",
    "    return (masks > 0)\n",
    "\n",
    "def _valid_box(x1,y1,x2,y2):\n",
    "    try:\n",
    "        x1=int(x1); y1=int(y1); x2=int(x2); y2=int(y2)\n",
    "    except Exception:\n",
    "        return False\n",
    "    return (x2 > x1) and (y2 > y1)\n",
    "\n",
    "def _clamp_xyxy(x1,y1,x2,y2,W,H):\n",
    "    x1 = max(0, min(int(x1), W-1))\n",
    "    y1 = max(0, min(int(y1), H-1))\n",
    "    x2 = max(0, min(int(x2), W))\n",
    "    y2 = max(0, min(int(y2), H))\n",
    "    if x2 <= x1: x2 = min(W, x1+1)\n",
    "    if y2 <= y1: y2 = min(H, y1+1)\n",
    "    return [x1,y1,x2,y2]\n",
    "\n",
    "def _area_box(bx):\n",
    "    x1,y1,x2,y2 = bx\n",
    "    return max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "def _mask_bbox(mask_bool: np.ndarray):\n",
    "    \"\"\"Tight bbox around a binary mask; returns [x1,y1,x2,y2] or None if empty.\"\"\"\n",
    "    ys, xs = np.where(mask_bool)\n",
    "    if ys.size == 0:\n",
    "        return None\n",
    "    y1, y2 = ys.min(), ys.max() + 1\n",
    "    x1, x2 = xs.min(), xs.max() + 1\n",
    "    return [int(x1), int(y1), int(x2), int(y2)]\n",
    "\n",
    "def _frac_inside(mask_bool: np.ndarray, box_xyxy) -> float:\n",
    "    \"\"\"\n",
    "    Fraction of the *mask pixels* that lie inside the box.\n",
    "    1.0 → mask fully inside the box.\n",
    "    \"\"\"\n",
    "    H, W = mask_bool.shape\n",
    "    x1,y1,x2,y2 = _clamp_xyxy(*box_xyxy, W, H)\n",
    "    total = int(mask_bool.sum())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    inside = int(mask_bool[y1:y2, x1:x2].sum())\n",
    "    return inside / float(total)\n",
    "\n",
    "def _overlap_frac_of_box(mask_bool: np.ndarray, box_xyxy) -> float:\n",
    "    \"\"\"\n",
    "    Fraction of the *box area* that is covered by the mask.\n",
    "    0.0 → mask misses the box; 1.0 → mask fully covers the box.\n",
    "    \"\"\"\n",
    "    H, W = mask_bool.shape\n",
    "    x1,y1,x2,y2 = _clamp_xyxy(*box_xyxy, W, H)\n",
    "    box_area = max(1, (x2 - x1) * (y2 - y1))\n",
    "    inter = int(mask_bool[y1:y2, x1:x2].sum())\n",
    "    return inter / float(box_area)\n",
    "\n",
    "def _find_label_col(df: pd.DataFrame) -> str | None:\n",
    "    for c in LABEL_CANDIDATES:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _label_rule_keep_indices(label, masks, box_xyxy, **_):\n",
    "    return [i for i, m in enumerate(masks) if _frac_inside((m > 0), box_xyxy) >= ANY_INSIDE_FRAC]\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    sam = pipeline(\"mask-generation\", model=MODEL_ID, device=device)\n",
    "\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df = df[:1]\n",
    "\n",
    "    # label column\n",
    "    label_col = _find_label_col(df)\n",
    "\n",
    "    # optional: remove discard-labeled rows\n",
    "    if SKIP_DISCARD and label_col is not None:\n",
    "        df = df[df[label_col].astype(str).str.lower() != \"discard\"]\n",
    "\n",
    "    # sanity\n",
    "    for c in [IMG_COL] + BOX_COLS:\n",
    "        if c not in df.columns:\n",
    "            raise SystemExit(f\"CSV missing column: {c}\")\n",
    "\n",
    "    # numeric boxes + drop bad\n",
    "    for c in BOX_COLS:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[IMG_COL] + BOX_COLS)\n",
    "\n",
    "    # group bboxes by image (keep label per row too)\n",
    "    groups = {}\n",
    "    for i, r in df.iterrows():\n",
    "        ip = Path(str(r[IMG_COL]))\n",
    "        if not ip.exists():\n",
    "            continue\n",
    "        x1,y1,x2,y2 = [int(r[c]) for c in BOX_COLS]\n",
    "        if not _valid_box(x1,y1,x2,y2):\n",
    "            continue\n",
    "        label = str(r[label_col]) if label_col is not None else \"\"\n",
    "        groups.setdefault(ip, []).append((i, [x1,y1,x2,y2], label))\n",
    "\n",
    "    if not groups:\n",
    "        raise SystemExit(\"No valid images/boxes found.\")\n",
    "\n",
    "    for img_path, rows in groups.items():\n",
    "        im = _open_pil(img_path)\n",
    "        W, H = im.size\n",
    "\n",
    "        # Generate ALL masks once for this image\n",
    "        try:\n",
    "            pred = sam(image=im)\n",
    "        except TypeError:\n",
    "            pred = sam(im)\n",
    "        masks_all = _extract_masks(pred)\n",
    "        if masks_all is None or masks_all.shape[0] == 0:\n",
    "            print(f\"[skip] no masks from SAM2: {img_path.name}\")\n",
    "            continue\n",
    "\n",
    "        kept_masks   = []\n",
    "        kept_rows    = []\n",
    "        kept_boxes   = []\n",
    "        kept_labels  = []\n",
    "\n",
    "        # Apply label-specific selection per bbox\n",
    "        for rid, box, label in rows:\n",
    "            bx = _clamp_xyxy(*box, W, H)\n",
    "            keep_idx = _label_rule_keep_indices(label, masks_all, bx)\n",
    "            for i_m in keep_idx:\n",
    "                kept_masks.append(masks_all[i_m].astype(np.uint8))\n",
    "                kept_rows.append(int(rid))\n",
    "                kept_boxes.append(bx)\n",
    "                kept_labels.append(str(label))\n",
    "\n",
    "        if not kept_masks:\n",
    "            print(f\"[ok] {img_path.name}: kept 0 (SAM had {masks_all.shape[0]})\")\n",
    "            continue\n",
    "\n",
    "        masks_arr   = np.stack(kept_masks, axis=0)               # (K,H,W) uint8\n",
    "        rows_arr    = np.array(kept_rows, dtype=np.int32)        # (K,)\n",
    "        boxes_arr   = np.array(kept_boxes, dtype=np.int32)       # (K,4)\n",
    "        labels_arr  = np.array(kept_labels, dtype=object)        # (K,)\n",
    "\n",
    "        out_path = OUT_DIR / (img_path.stem + \".npz\")\n",
    "        tmp = out_path.with_suffix(\".tmp.npz\")\n",
    "        np.savez_compressed(\n",
    "            tmp,\n",
    "            masks=masks_arr,\n",
    "            det_row_indices=rows_arr,     # which CSV row/bbox this mask is for\n",
    "            det_boxes_xyxy=boxes_arr,     # the bbox used for selection\n",
    "            det_labels=labels_arr,        # label string used for rules\n",
    "            image_size=np.array([H, W], dtype=np.int32),\n",
    "            params=np.array(\n",
    "                [INSIDE_THRESH, COVER_THRESH, OVERLAP_MIN_FRAC, BARN_MIN_SIZE_RATIO],\n",
    "                dtype=np.float32\n",
    "            ),\n",
    "        )\n",
    "        os.replace(tmp, out_path)\n",
    "        print(f\"[ok] {img_path.name}: kept {masks_arr.shape[0]} masks (SAM had {masks_all.shape[0]})\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6c516d-5b53-48cf-8a9b-bd607149d19e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/wyr6fx/.local/lib/python3.11/site-packages (4.55.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: filelock in /home/wyr6fx/.local/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/wyr6fx/.local/lib/python3.11/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/wyr6fx/.local/lib/python3.11/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/wyr6fx/.local/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/wyr6fx/.local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/wyr6fx/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wyr6fx/.local/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wyr6fx/.local/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m175.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.4\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.4:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.4\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Found existing installation: transformers 4.55.22m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.55.2:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.55.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\u001b[33m  WARNING: The scripts transformers and transformers-cli are installed in '/home/wyr6fx/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.22.0 transformers-4.56.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666121e-9a78-4c08-b138-8002473431b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
